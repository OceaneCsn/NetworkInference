---
title: "Thresholding Method for GENIE3 network inference"
author: "Oceane Cassan"
date: \today
output: 
  rmdformats::readthedown:
  fig_width: 12
highlight: kate
includes:
  after_body: footer.html
---
  
  
  
```{r knitr_init, echo=FALSE, cache=FALSE}
library(knitr, warn.conflicts = F, quietly = T)
library(rmdformats, warn.conflicts = F, quietly = T)
options(Encoding="UTF-8")
## Global options
options(max.print="75")
opts_chunk$set(cache=FALSE,
               prompt=FALSE,
               tidy=TRUE,
               comment=NA,
               message=FALSE,
               warning=FALSE,
               fig.align = "center")
opts_knit$set(width=75)


setwd("D:/These/NetworkInference")

suppressMessages(library(igraph, warn.conflicts = F, quietly = T))
suppressMessages(library(visNetwork, warn.conflicts = F, quietly = T))
suppressMessages(library(genefilter, warn.conflicts = F, quietly = T))
suppressMessages(library(ggplot2, warn.conflicts = F, quietly = T))
suppressMessages(library(GENIE3, warn.conflicts = F, quietly = T))
suppressMessages(library(stringr, warn.conflicts = F, quietly = T))

```

# Contexte

GENIE3 est une méthode d'inférence de Gene Regulatory Networks. Elle prend en entrée une liste de gènes cibles, une liste de TFs, et une matrice donnant les profils d'expression de tous ces gènes parmis différentes conditions.


GENIE3 détermine par Random Forests, pour chaque profil d'expression d'un gène cible l'influence/importance de l'expression de chaque TF renseigné.


For each input gene, considered as a **target gene**, a Random Forest is fitted. This random forest is composed of N regression trees, which objective is to predict the expression of the target gene using the regulators as regressors on the tree splits. Each tree can then provide an "importance" value for the regulators, based on the varaiance reduction caused by the regulators in the tree splits. A robust importance value can be computed by averaging the values of all the trees.


" Several variable importance measures have been proposed in the literature for tree-based methods. In our experiment, we consider a measure which at each test node computes the total reduction of the variance of the output variable due to the split," (GENIE3 publication)

Il en résulte une matrice d'adjascence non sparse, contenant une valeur d'importance pour toutes les paires TFs-cibles possibles.

On cherche à déterminer une valeur d'importance seuil, au dessus de laquelle on garderait les interractions TFs-gènes cibles pour construire notre réseau.

Certaines méthodes ont déja été envisagées ou essayées :
  
+ **Hard thresholding** : pour l'instant, on a fixé un seuil assez arbitraire (seulement basé sur le nombre d'arrêtes qui rend le réseau visualisable et analisable). On a fixé un réseau qui contient les 3000 arrêtes de poids le plus fort.

+ **BRANE CUT** : a l'air très inétressante mais codée en Matlab et requiert des données générées en Matlab. J'aime peu l'idée d'utiliser matlab (elitiste, pas vraiment dans les principes open source), et en plus si on veut mettre notre méthode à disposition, ça complique beaucoup les choses d'appeler du code matlab en dehors du R.

+ **Backboning** : Intéressant mais repose sur des hypothèses que nous ne sommes pas sûrs de vérifier dans notre cas particulier, notament la loi binomiale pour le poids d'une arrête. Module python.

Dans la litérature, certains fixent des seuils arbitraires, d'autres utilisent des données extrenes de validation pour fixer le nombre d'arrête maximisant la performance prédictive du réseau. Nous n'en avons pas dans notre cas.

Nous avons donc décidé de penser à une méthode que nous pourrions implémenter et tester par nous même, en R, pour répondre à nos attentes/contexte particulier.

# Description de la méthode

L'idée est de détacher les variables (TFs) influentes dans l'explication de l'expression des gènes cibles de l'aléatoire, du bruit de fond des données.
Or, nous n'avons à priori pas d'idée de cette valeur qui nous permettrait de **trancher entre valeur d'importance informative, et valeur d'importance non informative**.

L'idée est inspirée d'une méthode que Sophie avait déjà rencontrée sur des Random Forest. 

+ On crée des variables issues de l'**expression moyenne des TFs**, qui ne portent donc pas plus d'information que ce que les autres TFs peuvent apporter. 
On appelle ces variables les variables random, ou espionnes. En pratique, on les lire dans une loi de Poisson dont le paramètre est la moyenne de l'expression de tous les TFs. (Il s'agit d'un vecteur d'expressions, de dimension le nombre de conditions d'expression dans jeu de données)

+ On insére ces variables au jeu de données, puis on utilise GENIE3 sur ce jeu de données.

+ En sortie, nous regardons des valeurs d'importance pour chaque paire gène cible-variable random. La distribution des ces importances correspond à la distribution de notre **hypothèse nulle**, c'est à dire **la distribution des importances qu'on attend pour des TFs non informatifs**.

+ Pour chaque paire (vrai)TF-gène cible, on place l'importance associée sur la distribution précédente. Si l'importance est supérieure au quantile à 0.001 de cette distribution, un garde cette interaction TF-cible pour notre réseau. Re-Formulation de cette étape : une interaction est gardée si elle a moins de 1 millième de chances de se produire dans le cas ou le TF n'est pas informatif pour la cible.

+ On obtient une liste très réduite d'interactions que nous utilisons pour construire le réseau final.

### Fonction R pour cette méthode : 

```{r method}

#' Inserts the random variables
#'
#' @param normalized.count expression data to which we wan't to add the spy variables
#' @param regressors regulators to use to generate the spies
#' @param n_spies number of random varaibles
#' @param keepColMeans weather or not to use means specific to the conditions or a global mean
#'
#' @return the expression dataframe with spy variables inside
#' @export
insertSpyVariable <- function(normalized.count, regressors = row.names(normalized.count), 
                              n_spies = 3, keepColMeans = T){
  means <- colMeans(normalized.count[regressors,])
  
  spies <- data.frame(normalized.count[sample(rownames(normalized.count), size=n_spies),], 
                      row.names = paste0("spy_",seq(1:n_spies)))
  for(cond in colnames(normalized.count)){
    if(keepColMeans) spies[,cond] <- rpois(lambda = means[cond], n = n_spies)
    else spies[,cond] <- rpois(lambda = mean(means), n = n_spies)
  }
  normalized.count <- rbind.data.frame(normalized.count, spies)
  print(tail(normalized.count))
  return(normalized.count)
}

insertSpyVariableEmprical <- function(normalized.count, regressors = row.names(normalized.count), 
                              n_spies = 12, keepColMeans = T){
  
  tfs_expressions <- as.vector(normalized.count[regressors,])
  
  spies <- data.frame(normalized.count[sample(rownames(normalized.count), size=n_spies),], 
                      row.names = paste0("spy_",seq(1:n_spies)))
  
  for(cond in colnames(normalized.count)){
    spies[,cond] <- sample(tfs_expressions, size = n_spies)
  }
  
  
  normalized.count <- rbind.data.frame(normalized.count, spies)
  print(tail(normalized.count))
  return(normalized.count)
}

#' Function to combine genie3 and our thresholding method
#'
#' @param normalized.count expression data
#' @param regressors regulators (TFs) names in normalized.count
#' @param targets target genes
#' @param nTrees number of trees in GENIE3
#' @param nCores number of cores in GENIE3
#' @param pval quantile to use on the null distribution
#' @param varNorm weather to normalize the expression data to have 
#' a unit variance
#' @param n_spies number of random variables
#' @param keepColMeans weather or not to use means specific to the conditions or a global mean
#' @param returnNlinks weather or not to return only the number of links, not the network
#'
#' @return the infered graph, or the number of links of the inferred graph
genie3 <- function(normalized.count, regressors=NA, targets=NA, nTrees=1000, nCores=5, 
                  pval = 0.05, varNorm = F, n_spies = 5, keepColMeans = T, returnNlinks = F,
                  new_spies = F){
  
  

#   ____________________________________________________________________________
#   network inference                                                       ####
  if(new_spies){
    normalized.count <- insertSpyVariableEmprical(normalized.count, regressors,
                                        n_spies = n_spies)
  }
  else{
    normalized.count <- insertSpyVariable(normalized.count, regressors,
                                        n_spies = n_spies, keepColMeans = keepColMeans)
  }
  
  
  regressors <- intersect(rownames(normalized.count),regressors)
  regressors = c(regressors, rownames(normalized.count)[grepl('spy_', rownames(normalized.count))])

  if (varNorm) normalized.count <- normalized.count/rowSds(normalized.count)

  mat <- GENIE3(as.matrix(normalized.count), regulators = regressors, targets = targets, 
                treeMethod = "RF", K = "sqrt", nTrees = nTrees, nCores = nCores, verbose = T)
  
  
#   ____________________________________________________________________________
#   thresholding                                                            ####

  
  thrs <- c(mat[grepl('spy_', rownames(mat)),])
  threshold = quantile(thrs, probs = 1-pval)
  print(threshold)

  links <- getLinkList(mat, threshold = threshold)
  links <- links[!grepl('spy_', links[,1]),]
  if (returnNlinks) return(dim(links)[1]) 
  print(paste0("Number of links : ", dim(links)[1]))
  g <- graph_from_data_frame(links, directed = T)
  return(list(net = g, impSpies = thrs, impTFs = thrs <- c(mat[!grepl('spy_', rownames(mat)),])))
}

# returns the pvalue for one importance value, by placing it on the
# empirical null distribution
getPvalue <- function(value, null_distribution){
  return(sum(null_distribution > value)/length(null_distribution))
}

getCorrectedPvalues <- function(null_distribution, importances_to_test, method = 'fdr'){
  pvalues <- sapply(importances_to_test, getPvalue, null_distribution = null_distribution)
  fdr <- p.adjust(pvalues, method = method)
  return(fdr)
}


```

# Exécution de la méthode

Nous exécutons cette méthode en inférant un réseau sur les gènes **DE entre cnF et CnF** (1309 gènes), et en utilisant les valeurs d'expression des gènes dans les conditions **cNF, cnF, CNF, CnF**. (3*4 colonnes dans la matrice d'expression). On prend une pvalue (quantile à 0.001), on ne normalize pas les profils d'expression à une variance unitaire, et on prend 10 variables espionnes tirées dans des lois de Poisson de moyenne la moyenne globale.

```{r run}
source("Funtions/Network_functions.R")

load("./Data/DEGsListsFiltered.RData")
load("./Data/PlnTFBDRegulatorsList.RData")
load("./Data/normalized.count_At.RData")
load("./Data/OntologyAllGenes.RData")


pval = 0.001
# DE genes
genes <- DEGs[["cnF CnF"]]
print(length(genes))

# expression data
normalized.count <- normalized.count[,grepl('F', colnames(normalized.count))]
head(normalized.count)

# TFs
regressors = intersect(TF$AGI, genes)
print(length(regressors))

# inference and thresholding
res <- genie3(normalized.count, regressors = regressors, 
              targets = genes, varNorm = F, pval = pval, n_spies = 20, 
              keepColMeans = F)
net <- res$net
length(V(net)) # nombre de genes du reseau
length(E(net)) # nombre d'arretes

```


Les arrêtes que nous conservons correpondent donc à l'aire bleue à partir du seuil.

## le réseau en sortie 


```{r net}
networkToData <- function(net, ontologies, TF){
  data <- toVisNetworkData(net)
  data$nodes$Ontology <- ontologies[match(data$nodes$id, ontologies$ensembl_gene_id), "external_gene_name"]
  data$nodes$description <- ontologies[match(data$nodes$id, ontologies$ensembl_gene_id), "description"]
  data$nodes$group <- ifelse(data$nodes$id %in% TF$AGI, "Regulator", "Target Gene")
  
  data$nodes$label <- data$nodes$Ontology
  data$edges$color <- '#333366'
  data$edges$value <- data$edges$weight
  data$edges$Regulator_Name <-
    ontologies[match(data$edges$from, ontologies$ensembl_gene_id), ]$external_gene_name
  data$nodes$description <-
    ifelse(
      grepl("\\[", data$nodes$description),
      str_split_fixed(data$nodes$description, "\\[", 2)[, 1],
      data$nodes$description
    )
  data$edges$Target_Name <-
    ontologies[match(data$edges$to, ontologies$ensembl_gene_id), ]$external_gene_name
  return(data)
}

data <- networkToData(net, ontologies, TF)
plotNetwork(data)
```

# Visualisation de la correction des tests multiples

Comme on teste un nombre très grand valeurs d'importances (176000 environ pour ce réseau), on choisit de corriger les pvalues avec la méthode du FDR (https://en.wikipedia.org/wiki/False_discovery_rate#Benjamini%E2%80%93Hochberg_procedure).

On place toutes les valeurs d'importance sur la distribution de l'hypothèse nulle pour obtenir leurs pvalues.

On utilise ensuite la fonction p.adjust sur ce vecteur de pvalues en spécifiant le type de correction.

```{r fdr}

spies <- res$impSpies
tfs <- res$impTFs

pvals <- sapply(tfs, getPvalue, null_distribution=spies)


fdr <- getCorrectedPvalues(spies, tfs, method = "fdr")
bonfer <- getCorrectedPvalues(spies, tfs, method = "bonferroni")

summary(bonfer)
d <- data.frame("p_values" = c(pvals, fdr), Correction = c(rep("none", length(pvals)), rep("fdr", length(fdr))))


p <- ggplot(data = d, aes(x = p_values, fill = Correction)) +
  geom_density(alpha = 0.3)

p + ggtitle("Distribution des p values, avec correction BH (fdr) ou non")

```

On constate que toutes les pvalues, après correction, sont shiftées, et on n'en a quasi plus de significatives si on prend des seuils classiques autour de 5, 10 ou 1%...

# Distribution des valeurs d'importance

On s'attend à voir une distribution des TFs plus étalée vers de fortes importances que ne le serait celle des variables espionnes.

C'est en effet ce que l'on constate :

```{r dist}
spies <- res$impSpies
tfs <- res$impTFs

print(head(tfs))
print(head(spies))
d <- data.frame("Importance" = c(tfs, spies), Variable = c(rep("TF", length(tfs)), rep("Spy", length(spies))))

p <- ggplot(data = d, aes(x = Importance, fill = Variable)) +
  geom_density(alpha = 0.3) + geom_vline(xintercept = quantile(spies, probs = 1 - pval),
                                         linetype="dotted", size=1.5) 

p + ggtitle("Distribution des importances pour les variables espionnes et les vrais TFs")

p + ylim(c(0,5)) + ggtitle("Zoom sur la partie avec le seuil (quantile à  1/1000)")

```

On note que comparé au nombre total possible d'arrêtes (176 000), on en sélectionne très peu.

# Variance des variables espionnes : sont-elles de "vraies" espionnes?

Si les variables espionnes générées avec une loi de Poisson ne sont en fait pas aussi dispersées que les valeurs d'expression des vrais TFs, cela pourrait les différencier, et donc biaiser notre méthode. On affiche donc leur variance pour s'en rendre compte, comparé à celle des TFs :

```{r var_espionnes}

exp <- insertSpyVariable(normalized.count, regressors= intersect(TF$AGI, genes), n_spies = 135, keepColMeans = F)
exp <- exp[rownames(exp)%in%intersect(TF$AGI, genes) | grepl("spy_", rownames(exp)),]

vars <- rowSds(exp)**2
tfs_vars <- vars[names(vars) %in% intersect(TF$AGI, genes)]
spy_vars <- vars[!names(vars) %in% intersect(TF$AGI, genes)]

spy_means <- rowMeans(exp[grepl('spy', rownames(exp)),])
summary(spy_means)


plot(spy_means, spy_vars)
d <- data.frame("Variance" = c(tfs_vars, spy_vars), Variable = c(rep("TF", length(tfs_vars)), rep("Spy", length(spy_vars))))

p <- ggplot(data = d, aes(y = sqrt(Variance), x = Variable, fill = Variable)) +
  geom_violin(alpha = 0.3) 

p + ggtitle("Distribution des sd pour les variables espionnes et les vrais TFs")

p <- ggplot(data = d, aes(y = sqrt(Variance), x = Variable, fill = Variable)) +
  geom_boxplot(alpha = 0.3) 

p + ggtitle("Distribution des sd pour les variables espionnes et les vrais TFs") 

summary(spy_vars)
summary(tfs_vars)

```


En effet! les variaances sont beaucoup plus petites, notre méthode ne parvient donc pas à créer des variables ressemblantes aux vrais TFs d'un point de vue de leur dispersion. Cela peut ensuite favoriser leur utilisation ou non dans les random forests. 

## Echantillonnage empirique des espionnes

On choisit donc plutôt d'échantillonner les espionnes dans les valeurs d'epxression des TFs existants, pour avoir une distribution similaire (qui devrait ressembler plutôt à une négative binomiale) :


```{r new_method}

insertSpyVariableEmprical <- function(normalized.count, regressors = row.names(normalized.count), 
                              n_spies = 12, keepColMeans = T){
  
  tfs_expressions <- as.vector(normalized.count[regressors,])
  
  spies <- data.frame(normalized.count[sample(rownames(normalized.count), size=n_spies),], 
                      row.names = paste0("spy_",seq(1:n_spies)))
  
  for(cond in colnames(normalized.count)){
    spies[,cond] <- sample(tfs_expressions, size = n_spies)
  }
  
  
  normalized.count <- rbind.data.frame(normalized.count, spies)
  print(tail(normalized.count))
  return(normalized.count)
}


exp <- insertSpyVariableEmprical(normalized.count, regressors= intersect(TF$AGI, genes), n_spies = 30)

exp <- exp[rownames(exp)%in%intersect(TF$AGI, genes) | grepl("spy_", rownames(exp)),]

vars <- rowSds(exp)**2
tfs_vars <- vars[names(vars) %in% intersect(TF$AGI, genes)]
spy_vars <- vars[!names(vars) %in% intersect(TF$AGI, genes)]

spy_means <- rowMeans(exp[grepl('spy', rownames(exp)),])
summary(spy_means)


plot(spy_means, spy_vars)
d <- data.frame("Variance" = c(tfs_vars, spy_vars), Variable = c(rep("TF", length(tfs_vars)), rep("Spy", length(spy_vars))))

p <- ggplot(data = d, aes(y = sqrt(Variance), x = Variable, fill = Variable)) +
  geom_violin(alpha = 0.3) 

p + ggtitle("Distribution des ecarts types pour les variables espionnes et les vrais TFs") 

p <- ggplot(data = d, aes(y = sqrt(Variance), x = Variable, fill = Variable)) +
  geom_boxplot(alpha = 0.3) 

p + ggtitle("Distribution des ecart types pour les variables espionnes et les vrais TFs") 

summary(spy_vars)
summary(tfs_vars)

```



Dans ce cas là, on se retrouve avec des variances de profils beaucoup plus grandes que celles des TFs. Je pense que c'est dû au fait que les valeurs d'expression moyennes entre TFs sont très différentes les unes de autres. Du coup, quand on pioche des valeurs d'expression au hasard dans les expressions des TFs, on crée des espionnes qui n'ont pas un niveau d'expression "cohérent", car il peut prendre des valeurs très fortes ou très faibles. Il faudrait pouvoir limiter la variation de l'expression des espionnes comme l'est celle des TFs autour de leur niveau d'expression moyen... Qui est certes plus dispersé qu'une loi de Poisson, mais moins que ce que l'on obtient là. Dans ce cas là, il faudrait peut être vraiment utiliser une loi négative binomiale plutôt que de tirer les expressions de manière empirique parmis toutes les valeurs des TFs.

## Centrage des expressions des TFs

```{r center}

n_spies = 130

cent_reg <- normalized.count[regressors,] - rowMeans(normalized.count[regressors,])
tfs_expressions <- as.vector(cent_reg)
hist(tfs_expressions, breaks = 60)
  
spies <- data.frame(normalized.count[sample(rownames(normalized.count), size=n_spies),], 
                    row.names = paste0("spy_",seq(1:n_spies)))
  
for(cond in colnames(normalized.count)){
  spies[,cond] <- sample(tfs_expressions, size = n_spies)
}

tfs_vars <- rowSds(cent_reg)

spy_vars <- rowSds(spies)


d <- data.frame("Variance" = c(tfs_vars, spy_vars), Variable = c(rep("TF", length(tfs_vars)), rep("Spy", length(spy_vars))))

p <- ggplot(data = d, aes(y = Variance, x = Variable, fill = Variable)) +
  geom_violin(alpha = 0.3) 

p + ggtitle("Distribution des ecarts types pour les variables espionnes et les vrais TFs") 

p <- ggplot(data = d, aes(y = Variance, x = Variable, fill = Variable)) +
  geom_boxplot(alpha = 0.3) 

p + ggtitle("Distribution des ecart types pour les variables espionnes et les vrais TFs") 


tfs_vars <- rowMeans(cent_reg)

spy_vars <- rowMeans(spies)


d <- data.frame("Variance" = c(tfs_vars, spy_vars), Variable = c(rep("TF", length(tfs_vars)), rep("Spy", length(spy_vars))))

p <- ggplot(data = d, aes(y = Variance, x = Variable, fill = Variable)) +
  geom_boxplot(alpha = 0.3) 

p + ggtitle("Distribution des moyennes pour les variables espionnes et les vrais TFs") 

```

On se retrouve avec des variances assez proches, et qui pourraient peut être être satisfaisantes.
Cependant, en echantillonnant des valeurs d'expression parmis toutes les expressions des TFs, on se retrouve avec des moyennes d'expressions qui valent toutes 0 pour les vrais TFs, et des moyennes non nulles pour les espionnes.


Par curiosité, on relance genie3 pour voir la distribution de l'importance de ces nouvelles espionnes par rapport aux vrais Tfs :


```{r run_empirical}


# inference and thresholding
res <- genie3(normalized.count, regressors = regressors, 
              targets = genes, varNorm = F, pval = pval, n_spies = 20, 
              keepColMeans = F, new_spies = T)
net <- res$net
length(V(net)) # nombre de genes du reseau
length(E(net)) # nombre d'arretes

spies <- res$impSpies
tfs <- res$impTFs

print(head(tfs))
print(head(spies))

d <- data.frame("Importance" = c(tfs, spies), Variable = c(rep("TF", length(tfs)), rep("Spy", length(spies))))

p <- ggplot(data = d, aes(x = Importance, fill = Variable)) +
  geom_density(alpha = 0.3) + geom_vline(xintercept = quantile(spies, probs = 1 - pval),
                                         linetype="dotted", size=1.5) 

p + ggtitle("Distribution des importances pour les variables espionnes et les vrais TFs")

p + ylim(c(0,5)) + ggtitle("Zoom sur la partie avec le seuil (quantile à  1/1000)")

```
On voit que les deux distributions sont beaucoup plus proches, celle des TFs diffère uniquement un peu sur la upper tail de la distribution, avec des valeurs d'importance plus élevées.
On retient avec cette méthode environ 3000 aretes.

Dans tous les cas, on est embêté car ces variables espionnes n'ont toujours pas une variance comparable à celle des TFs, donc le test peut encore être biaisé. Il faut trouver un meilleur moyen de les générer.

# Exploration paramétrique

La méthode repose cependant sur de nombreux paramètres, et explorer leur influence est nécessaire pour faire un choix.

Nous lançons donc la méthode plusieurs fois, pour chaque set de paramètres, et regardons le nombre d'arrêtes selectionnées au final (axe y). Les paramètres sont :


+ Le nombre de variables espionnes (axe x)

+ Si oui ou non les profils sont tous normalisés afin d'avoir une variance unitaire. (les deux lignes du graphe)

+ Si on tire les variables random dans une loi Poisson dont le paramètre est spécifique à la condition, ou si on prend la moyenne globale parmis toutes les conditions (les deux colonnes du graphe)

+ Le quantile choisi, correspond à la pvalue de notre test (couleur des points)

<img src="D:\These\NetworkAnalysisSophie\explorationGENIE3.png" align="center" alt="" width="1500"/>


<img src="D:\These\NetworkAnalysisSophie\explorationGENIE3zoom.png" align="center" alt="" width="1500"/>


On se rend compte qu'on n'a pas vraiment d'effet de la normalisation (étudié plus bas).

Ensuite, de prendre une moyenne non dépendant des conditions donne un plus grand nombre d'arrêtes, faisant penser qu'il s'agit d'un choix moins informatif pour nos variables randoms, et donc plus proche de notre hypothèse nulle.


Il faut des quantiles assez faibles pour avoir un nombre d'arrêtes raisonnable, on peut dire qu'entre 0.005 et 0.001 on est dans une bonne zone.

Le nombre de variables espionnes semble augmenter le nombre d'arrêtes sélectionnées, je ne sais pas encore exactement pourquoi, à continuer d'explorer.

# Version seuil gene specific

La méthode proposée précédement repose sur l'hypothèse que les valeurs d'importance de toutes les paires peuvent être directement comparées, et ne dépendent pas de caractèristiques propres aux gènes, comme leur variance ou expression moyenne.

Pour s'en assurer, nous avons implémenté une méthode qui, au lieu de se baser sur un quantile d'une distribution qui merge tous les gènes cibles, se base sur un seuil par gène.

On prend, pour chaque gène, l'importance maximale trouvé parmis les n variables espionnes générées.
Tous les TFs dont l'importance est supérieure à ce seuil pour ce gène sont gardés.

On refait donc une exploration paramétrique pour avec ou sans moyenne condition spécifique, pour plusieurs nombre de variables espionnes : 

<img src="D:\These\NetworkAnalysisSophie\explorationGENIE3GeneSpecific.png" align="center" alt="" width="1500"/>

On voit tout de sute que les ordres de grandeur du nombre de links gardés dans le réseau sont beaucoup trop grands pour avoir des réseaux interprêtables facilement (100 000 arrêtes, au minimum 20 000)...


On constate encore que le nombre de variables espionnes augmente le nombre d'arrêtes gardées.

Pour s'assurer du fait que la valeur d'importance calculée par GENIE3 ne dépend pas du gène, on trace l'importance maximale des variables espionnes pour chaque gène, en fonction de son coefficient de variation :

<img src="D:\These\NetworkAnalysisSophie\maxImpSdMean.png" align="center" alt="" width="1500"/>

La corrélation est faible (10%), justifiant que l'on puisse utiliser une methode de seuil non spécifique au gène telle que celle présentée dans un premier temps.

# Effet de la variance normalisée

A priori, on avait vu que la variance ne change pas trop les réseaux inférés, switch des arrêtes, mais on aimerait le quantifier. De plus, dans l'exploration paramétrique précédente, elle ne changeait pas le nombre d'arrêtes.


On choisit de calculer la correlation de spearman entre un vecteur d'importances des mêmes paires, calculées avec normalisation de la variance ou non.

Avant le test, on fixe qu'une valeur supérieure à 80% serait bien, sinon pas terrible.

```{r varnorm}

resNorm <- genie3(normalized.count, regressors = regressors, 
              targets = genes, varNorm = T, pval = pval, n_spies = 20, 
              keepColMeans = F)

tfs_norm <- resNorm$impTFs

d <- data.frame(impNorm = tfs_norm, imp = tfs)

ggplot(data = d, aes(x = log(imp), y = log(impNorm))) + geom_hex()

cor(tfs, tfs_norm, method = "spearman")
```
La corrélation est très forte, au dessus des 80%!.

Cela confirme que la normalisation de la variance ne semble pas nécessaire, car GENIE3 semble déjà avoir réglé la dépendance entre gènes et valeurs d'importance avec une étape de normalisation interne. En effet, les importances pour chaque gènes sont divisées par la somme de toutes les importances de ce gène cible là.

# CONCLUSION


Au terme des simulations et des tests, il semblerait que nous puissions nous orienter vers cette méthode.


Le choix du nombre de variables espionnes est encore un peu flou, et relativement peu influent. Nous pouvons supposer qu'il est mieux de privilégier un petit nombre de variables espionnes afin de ne pas interférer avec les combinatoires de TFs inférées par GENIE3, et ne pas risquer de diminuner le ratio signal sur bruit. On pourrait partir sur 10% du nombre de TFs dans le jeu de données.

Un point négatif est qu'il reste encore pas mal de variabilité dans les réseaux finaux (en terme de nombre de connexions), car ils dépendent pas mal du tirage initial des variables randoms. Si on lance plusieurs fois la méthode avec les mêmes paramètres, le nombre de connexions du réseau final peut varier de plusieurs centaines... souvent entre 800 et 1200 arrêtes pour les paramètres utilisés lors de l'exécution. On pourrait appliquer plusieurs fois la méthode et moyenner les seuils obtenus.

**Il reste à finir de traiter la question de la correction des tests multiples, trop conservatrice à cause du très grand nombre de tests.**


Il s'agit ici d'un **test empirique** que nous avons créé pour répondre à notre problème.
Au lieu de connaître théoriquement le distribution de l'importance du bruit de fond, ou background, des données, nous l'avons générée en introduisant des variables qui nous avons simulées sous cette hypothèse nulle.


Les résultats restent sujets à des choix pas toujours triviaux en termes de valeurs de paramètres, mais la sortie de notre méthode est plus interprêtable et utilisable que du hard thresholding.
En effet, plutôt que de fixer un seuil sur une valeur d'importance issue d'un random forest à priori peu parlante, nous pouvons travailler avec des pvalues, traduisant plus correctement notre volonté de stringeance.


Cela semble être une bonne base pour commencer à analyser et interprêter le réseau en des termes plus biologiques! 