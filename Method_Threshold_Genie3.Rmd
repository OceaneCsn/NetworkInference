---
title: "Thresholding Method for GENIE3 network inference"
author: "Oceane Cassan"
date: \today
output: 
  rmdformats::readthedown:
  fig_width: 12
highlight: kate
includes:
  after_body: footer.html
---
  
  
  
```{r knitr_init, echo=FALSE, cache=FALSE}
library(knitr, warn.conflicts = F, quietly = T)
library(rmdformats, warn.conflicts = F, quietly = T)
options(Encoding="UTF-8")
## Global options
options(max.print="75")
opts_chunk$set(cache=FALSE,
               prompt=FALSE,
               tidy=TRUE,
               comment=NA,
               message=FALSE,
               warning=FALSE,
               fig.align = "center")
opts_knit$set(width=75)


setwd("D:/These/NetworkInference")

suppressMessages(library(igraph, warn.conflicts = F, quietly = T))
suppressMessages(library(visNetwork, warn.conflicts = F, quietly = T))
suppressMessages(library(genefilter, warn.conflicts = F, quietly = T))
suppressMessages(library(ggplot2, warn.conflicts = F, quietly = T))
suppressMessages(library(GENIE3, warn.conflicts = F, quietly = T))
suppressMessages(library(stringr, warn.conflicts = F, quietly = T))

```

# Contexte

GENIE3 est une méthode d'inférence de Gene Regulatory Networks. Elle prend en entrée une liste de gènes cibles, une liste de TFs, et une matrice donnant les profils d'expression de tous ces gènes parmis différentes conditions.


GENIE3 détermine par Random Forests, pour chaque profil d'expression d'un gène cible l'influence/importance de l'expression de chaque TF renseigné.
" Several variable importance measures have been proposed in the literature for tree-based methods. In our experiment, we consider a measure which at each test node computes the total reduction of the variance of the output variable due to the split," (GENIE3 publication)

Il en résulte une matrice d'adjascence non sparse, contenant une valeur d'importance pour toutes les paires TFs-cibles possibles.

On cherche à déterminer une valeur d'importance seuil, au dessus de laquelle on garderait les interractions TFs-gènes cibles pour construire notre réseau.

Certaines méthodes ont déja été envisagées ou essayées :
  
+ **Hard thresholding** : pour l'instant, on a fixé un seuil assez arbitraire (seulement basé sur le nombre d'arrêtes qui rend le réseau visualisable et analisable). On a fixé un réseau qui contient les 3000 arrêtes de poids le plus fort.

+ **BRANE CUT** : a l'air très inétressante mais codée en Matlab et requiert des données générées en Matlab. J'aime peu l'idée d'utiliser matlab (elitiste, pas vraiment dans les principes open source), et en plus si on veut mettre notre méthode à disposition, ça complique beaucoup les choses d'appeler du code matlab en dehors du R.

+ **Backboning** : Intéressant mais repose sur des hypothèses que nous ne sommes pas sûrs de vérifier dans notre cas particulier, notament la loi binomiale pour le poids d'une arrête. Module python.


Nous avons donc décider de penser à une méthode que nous pourrions implémenter et tester par nous même, en R, pour répondre à nos attentes/contexte particulier.

# Description de la méthode

L'idée est de détacher les variables (TFs) influentes dans l'explication de l'expression des gènes cibles de l'aléatoire, du bruit de fond des données.
Or, nous n'avons à priori pas d'idée de cette valeur qui nous permettrait de **trancher entre valeur d'importance informative, et valeur d'importance non informative**.

L'idée est inspirée d'une méthode que Sophie avait déjà rencontrée sur des Random Forest. 

+ On crée des variables issues de l'**expression moyenne des TFs**, qui ne portent donc pas plus d'information que ce que les autres TFs peuvent apporter. 
On appelle ces variables les variables random, ou espionnes. En pratique, on les lire dans une loi de Poisson dont le paramètre est la moyenne de l'expression de tous les TFs. (Il s'agit d'un vecteur d'expressions, de dimension le nombre de conditions d'expression dans jeu de données)

+ On insére ces variables au jeu de données, puis on utilise GENIE3 sur ce jeu de données.

+ En sortie, nous regardons des valeurs d'importance pour chaque paire gène cible-variable random. La distribution des ces importances correspond à la distribution de notre **hypothèse nulle**, c'est à dire **la distribution des importances qu'on attend pour des TFs non informatifs**.

+ Pour chaque paire (vrai)TF-gène cible, on place l'importance associée sur la distribution précédente. Si l'importance est supérieure au quantile à 0.001 de cette distribution, un garde cette interaction TF-cible pour notre réseau. Re-Formulation de cette étape : une interaction est gardée si elle a moins de 1 millième de chances de se produire dans le cas ou le TF n'est pas informatif pour la cible.

+ On obtient une liste très réduite d'interactions que nous utilisons pour construire le réseau final.

### Fonction R relative pour cette méthode : 

```{r method}

#' Inserts the random variables
#'
#' @param normalized.count expression data to which we wan't to add the spy variables
#' @param regressors regulators to use to generate the spies
#' @param n_spies number of random varaibles
#' @param keepColMeans weather or not to use means specific to the conditions or a global mean
#'
#' @return the expression dataframe with spy variables inside
#' @export
insertSpyVariable <- function(normalized.count, regressors = row.names(normalized.count), 
                              n_spies = 3, keepColMeans = T){
  means <- colMeans(normalized.count[regressors,])
  
  spies <- data.frame(normalized.count[sample(rownames(normalized.count), size=n_spies),], 
                      row.names = paste0("spy_",seq(1:n_spies)))
  for(cond in colnames(normalized.count)){
    if(keepColMeans) spies[,cond] <- rpois(lambda = means[cond], n = n_spies)
    else spies[,cond] <- rpois(lambda = mean(means), n = n_spies)
  }
  normalized.count <- rbind.data.frame(normalized.count, spies)
  print(tail(normalized.count))
  return(normalized.count)
}

#' Function to combine genie3 and our thresholding method
#'
#' @param normalized.count expression data
#' @param regressors regulators (TFs) names in normalized.count
#' @param targets target genes
#' @param nTrees number of trees in GENIE3
#' @param nCores number of cores in GENIE3
#' @param pval quantile to use on the null distribution
#' @param varNorm weather to normalize the expression data to have 
#' a unit variance
#' @param n_spies number of random variables
#' @param keepColMeans weather or not to use means specific to the conditions or a global mean
#' @param returnNlinks weather or not to return only the number of links, not the network
#'
#' @return the infered graph, or the number of links of the inferred graph
genie3 <- function(normalized.count, regressors=NA, targets=NA, nTrees=5000, nCores=5, 
                  pval = 0.05, varNorm = F, n_spies = 5, keepColMeans = T, returnNlinks = F){
  
  normalized.count <- insertSpyVariable(normalized.count, regressors,
                                        n_spies = n_spies, keepColMeans = keepColMeans)
  
  regressors <- intersect(rownames(normalized.count),regressors)
  regressors = c(regressors, rownames(normalized.count)[grepl('spy_', rownames(normalized.count))])

  if (varNorm) normalized.count <- normalized.count/rowSds(normalized.count)

  mat <- GENIE3(as.matrix(normalized.count), regulators = regressors, targets = targets, 
                treeMethod = "RF", K = "sqrt", nTrees = nTrees, nCores = nCores, verbose = T)
  
  thrs <- c(mat[grepl('spy_', rownames(mat)),])
  threshold = quantile(thrs, probs = 1-pval)
  print(threshold)

  links <- getLinkList(mat, threshold = threshold)
  links <- links[!grepl('spy_', links[,1]),]
  if (returnNlinks) return(dim(links)[1]) 
  print(paste0("Number of links : ", dim(links)[1]))
  g <- graph_from_data_frame(links, directed = T)
  return(list(net = g, impSpies = thrs, impTFs = thrs <- c(mat[!grepl('spy_', rownames(mat)),])))
}
```

# Exécution de la méthode

Nous exécutons cette méthode en inférant un réseau sur les gènes **DE entre cnF et CnF** (1309 gènes), et en utilisant les valeurs d'expression des gènes dans les conditions **cNF, cnF, CNF, CnF**. (3*4 colonnes dans la matrice d'expression). On prend une pvalue (quantile à 0.001), on ne normalize pas les profils d'expression à une variance unitaire, et on prend 10 variables espionnes tirées dans des lois de Poisson de moyenne la moyenne globale.

```{r run}
source("Funtions/Network_functions.R")

load("./Data/DEGsListsFiltered.RData")
load("./Data/PlnTFBDRegulatorsList.RData")
load("./Data/normalized.count_At.RData")
load("./Data/OntologyAllGenes.RData")


pval = 0.001
# DE genes
genes <- DEGs[["cnF CnF"]]
print(length(genes))

# expression data
normalized.count <- normalized.count[,grepl('F', colnames(normalized.count))]
head(normalized.count)

# TFs
regressors = intersect(TF$AGI, genes)
print(length(regressors))

# inference and thresholding
res <- genie3(normalized.count, regressors = regressors, 
              targets = genes, varNorm = F, pval = pval, n_spies = 20, 
              keepColMeans = F)
net <- res$net
length(V(net)) # nombre de genes du reseau
length(E(net)) # nombre d'arretes

```


Les arrêtes que nous conservons correpondent donc à l'aire bleue à partir du seuil.

## le réseau en sortie 


```{r net}
networkToData <- function(net, ontologies, TF){
  data <- toVisNetworkData(net)
  data$nodes$Ontology <- ontologies[match(data$nodes$id, ontologies$ensembl_gene_id), "external_gene_name"]
  data$nodes$description <- ontologies[match(data$nodes$id, ontologies$ensembl_gene_id), "description"]
  data$nodes$group <- ifelse(data$nodes$id %in% TF$AGI, "Regulator", "Target Gene")
  
  data$nodes$label <- data$nodes$Ontology
  data$edges$color <- '#333366'
  data$edges$value <- data$edges$weight
  data$edges$Regulator_Name <-
    ontologies[match(data$edges$from, ontologies$ensembl_gene_id), ]$external_gene_name
  data$nodes$description <-
    ifelse(
      grepl("\\[", data$nodes$description),
      str_split_fixed(data$nodes$description, "\\[", 2)[, 1],
      data$nodes$description
    )
  data$edges$Target_Name <-
    ontologies[match(data$edges$to, ontologies$ensembl_gene_id), ]$external_gene_name
  return(data)
}

data <- networkToData(net, ontologies, TF)
plotNetwork(data)
```


# Distribution des valeurs d'importance

On s'attend à voir une distribution des TFs plus étalée vers de fortes importances que ne le serait celle des variables espionnes.

C'est en effet ce que l'on constate :

```{r dist}

spies <- res$impSpies
tfs <- res$impTFs

d <- data.frame("Importance" = c(tfs, spies), Variable = c(rep("TF", length(tfs)), rep("Spy", length(spies))))

p <- ggplot(data = d, aes(x = Importance, fill = Variable)) +
  geom_density(alpha = 0.3) + geom_vline(xintercept = quantile(spies, probs = 1 - pval),
                                         linetype="dotted", size=1.5) 

p + ggtitle("Distribution des importances pour les variables espionnes et les vrais TFs")

p + ylim(c(0,5)) + ggtitle("Zoom sur la partie avec le seuil (quantile à  1/1000)")

```

On note que comparé au nombre total possible d'arrêtes (176 000), on en sélectionne très peu.

# Exploration paramétrique

La méthode repose cependant sur de nombreux paramètres, et explorer leur influence est nécessaire pour faire un choix.

Nous lançons donc la méthode plusieurs fois, pour chaque set de paramètres, et regardons le nombre d'arrêtes selectionnées au final (axe y). Les paramètres sont :


+ Le nombre de variables espionnes (axe x)

+ Si oui ou non les profils sont tous normalisés afin d'avoir une variance unitaire. (les deux lignes du graphe)

+ Si on tire les variables random dans une loi Poisson dont le paramètre est spécifique à la condition, ou si on prend la moyenne globale parmis toutes les conditions (les deux colonnes du graphe)

+ Le quantile choisi, correspond à la pvalue de notre test (couleur des points)

<img src="D:\These\NetworkAnalysisSophie\explorationGENIE3.png" align="center" alt="" width="1500"/>


<img src="D:\These\NetworkAnalysisSophie\explorationGENIE3zoom.png" align="center" alt="" width="1500"/>


On se rend compte qu'on n'a pas vraiment d'effet de la normalisation (étudié plus bas).

Ensuite, de prendre une moyenne non dépendant des conditions donne un plus grand nombre d'arrêtes, faisant penser qu'il s'agit d'un choix moins informatif pour nos variables randoms, et donc plus proche de notre hypthèse nulle.


Il faut des quantiles assez faibles pour avoir un nombre d'arrêtes raisonnable, on peut dire qu'entre 0.005 et 0.001 on est dans une bonne zone.

Le nombre de vraibles espionnes semble augmenter le nombre d'arrêtes sélectionnées, je ne sais pas encore exactement pourquoi.

# Version seuil gene specific

La méthode proposée précédement repose sur l'hypothèse que les valeurs d'importance de toutes les paires peuvent être directement comparées, et ne dépendent pas de caractèristiques propres aux gènes, comme leur variance ou expression moyenne.

Pour s'en assurer, nous avons implémenté une méthode qui, au lieu de se baser sur un quantile d'une distribution qui merge tous les gènes cibles, se base sur un seuil par gène.

On prend, pour chaque gène, l'importance maximale trouvé parmis les n variables espionnes générées.
Tous les TFs dont l'importance est supérieure à ce seuil pour ce gène sont gardés.

On refait donc une exploration paramétrique pour avec ou sans moyenne condition spécifique, pour plusieurs nombre de variables espionnes : 

<img src="D:\These\NetworkAnalysisSophie\explorationGENIE3GeneSpecific.png" align="center" alt="" width="1500"/>

On voit tout de sute que les ordres de grandeur du nombre de links gardés dans le réseau sont beaucoup trop grands pour avoir des réseaux interprêtables facilement (100 000 arrêtes, au minimum 20 000)...


On constate encore que le nombre de variables espionnes augmente le nombre d'arrêtes gardées.

Pour s'assurer du fait que la valeur d'importance calculée par GENIE3 ne dépend pas du gène, on trace l'importance maximale des variables espionnes pour chaque gène, en fonction de son coefficient de variation :

<img src="D:\These\NetworkAnalysisSophie\maxImpSdMean.png" align="center" alt="" width="1500"/>

La corrélation est faible (10%), justifiant que l'on puisse utiliser une methode de seuil non spécifique au gène telle que celle présentée dans un premier temps.

# Effet de la variance normalisée

A priori, on avait vu que la variance ne change pas trop les réseaux inférés, switch des arrêtes, mais on aimerait le quantifier. De plus, dans l'exploration paramétrique précédente, elle ne changeait pas le nombre d'arrêtes.


On choisit de calculer la correlation de spearman entre un vecteur d'importances des mêmes paires, calculées avec normalisation de la variance ou non.

Avant le test, on fixe qu'une valeur supérieure à 80% serait bien, sinon pas terrible.

```{r varnorm}

resNorm <- genie3(normalized.count, regressors = regressors, 
              targets = genes, varNorm = T, pval = pval, n_spies = 20, 
              keepColMeans = F)

tfs_norm <- resNorm$impTFs

d <- data.frame(impNorm = tfs_norm, imp = tfs)

ggplot(data = d, aes(x = log(imp), y = log(impNorm))) + geom_hex()

cor(tfs, tfs_norm, method = "spearman")
```
La corrélation est très forte, au dessus des 80%!.

Cela confirme que la normalisation de la variance ne semble pas nécessaire, car GENIE3 semble déjà avoir réglé la dépendance entre gènes et valeurs d'importance avec une étape de normalisation interne. En effet, les importances pour chaque gènes sont divisées par la somme de toutes les importances de ce gène cible là.

# CONCLUSION


Au terme des simulations et des tests, il semblerait que nous puissions nous orienter vers cette méthode, en définissant un quantile assez petit, et en prenant  une moyenne globale comme paramètre des lois de Poisson de nos variables espionnes.


Le choix du nombre de variables espionnes est encore un peu flou, et relativement peu influent. Nous pouvons supposer qu'il est mieux de privilégier un petit nombre de variables espionnes afin de ne pas interférer avec les combinatoires de TFs inférées par GENIE3, et ne pas risquer de diminuner le ratio signal sur bruit. 

Un point négatif est qu'il reste encore pas mal de variabilité dans les réseaux finaux (en terme de nombre de connexions), car ils dépendent pas mal du tirage initial des variables randoms.


Il s'agit ici d'un **test empirique** que nous avons créé pour répondre à notre problème.
Au lieu de connaître théoriquement le distribution de l'importance du bruit de fond, ou background, des données, nous l'avons générée en introduisant des variables qui nous avons simulées sous cette hypothèse nulle.


Les résultats restent sujets à des choix pas toujours triviaux en termes de valeurs de paramètres, mais la sortie de notre méthode est plus interprêtable et utilisable que du hard thresholding.
En effet, plutôt que de fixer un seuil sur une valeur d'importance issue d'un random forest à priori peu informative, nous pouvons travailler avec des pvalues, traduisant plus correctement notre volonté de stringeance.


Cela semble être une bonne base pour commencer à analyser et interprêter le réseau en des termes plus biologiques! 